# bank transaction user classification

[![Powered by Kedro](https://img.shields.io/badge/powered_by-kedro-ffc900?logo=kedro)](https://kedro.org)
![NumPy](https://img.shields.io/badge/numpy-013243?logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/pandas-150458?logo=pandas&logoColor=white)
![Scikit-Learn](https://img.shields.io/badge/scikit--learn-F7931E?logo=scikitlearn&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-EB5E28?logo=xgboost&logoColor=white)
![Matplotlib](https://img.shields.io/badge/matplotlib-11557C?logo=plotly&logoColor=white)
![Seaborn](https://img.shields.io/badge/seaborn-4C72B0)

![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-active-success)


## **ğŸ“– Deskripsi**
### **Masalah Bisnis**
Bank memiliki jumlah nasabah yang besar dengan pola transaksi yang sangat beragam. Tanpa pemahaman mendalam tentang perilaku transaksi, sulit untuk

* Mengidentifikasi segmen nasabah yang berbeda.
* Menawarkan produk yang tepat.
* Mengurangi risiko churn (nasabah berhenti menggunakan layanan).
* Meningkatkan efektivitas pemasaran dan manajemen risiko.
  
### **Tujuan Utama**
Mengelompokkan nasabah berdasarkan pola transaksi mereka (misalnya frekuensi transaksi, jenis transaksi, nominal, merchant, dsb.) menggunakan algoritma classification agar bank memahami karakteristik masing-masing segmen yang telah di hasilkan dari model clustering.

### **Nilai tambah**
Hasil dari klasifikasi dapat digunakan untuk
* **Personalisasi produk finansial** â†’ misal kartu kredit, deposito, pinjaman, atau investment product.
* **Efisiensi pemasaran** â†’ kampanye bisa ditargetkan ke segmen tertentu.
* **Mengenali nasabah berisiko tinggi** â†’ deteksi fraud atau transaksi tidak wajar lebih cepat.
* **Meningkatkan retensi** â†’ strategi mempertahankan nasabah disesuaikan berdasarkan perilaku.
* **Mendukung keputusan bisnis** â†’ manajemen bisa melihat komposisi nasabah secara real-time.

### **Target audience**
* **Tim Data & Analytics** â†’ untuk membuat model dan insight.
* **Tim Marketing** â†’ untuk menjalankan kampanye yang lebih tepat sasaran.
* **Tim Product Banking** â†’ mendesain produk sesuai kebutuhan segmen.
* **Manajemen Bank** â†’ bahan pengambilan keputusan.
* (Opsional) **Tim Risk/Fraud** â†’ memahami perilaku mencurigakan berdasarkan cluster.

## **ğŸ¯ Business Understanding**

### **Problem Statement**
Bank memiliki data transaksi nasabah yang sangat besar dan beragam, namun belum dimanfaatkan secara optimal untuk memahami perilaku dan kebutuhan nasabah. Akibatnya, bank kesulitan menentukan strategi pemasaran yang tepat, menawarkan produk yang relevan, serta mengidentifikasi kelompok nasabah yang berisiko tinggi atau berpotensi churn. Diperlukan sebuah model yang mampu mengelompokkan nasabah berdasarkan pola transaksi mereka sehingga bank dapat mengambil keputusan lebih cepat, tepat, dan berbasis data.

### **Objectives**

* [ ] **Tujuan 1:** Menghasilkan label nasabah menggunakan model clustering (misalnya K-Means) untuk membentuk segmentasi awal berdasarkan pola transaksi.
* [ ] **Tujuan 2:** Membangun model classification yang mampu memprediksi kelas/segmen nasabah baru berdasarkan fitur transaksi mereka dengan akurasi yang stabil.
* [ ] **Tujuan 3:** Mengidentifikasi fitur-fitur transaksi yang paling berpengaruh dalam menentukan kelas/segmen nasabah.
* [ ] **Tujuan 4:** Menyediakan dashboard atau visualisasi untuk memonitor distribusi kelas, performa model, serta perubahan perilaku nasabah dari waktu ke waktu.

### **Success Metrics**

#### **Bisnis Metrics**
##### **1. Peningkatan efektivitas targeting**

* Meningkatkan response rate kampanye berdasarkan segmen minimal **> 10%**.
* Atau peningkatan konversi produk per segmen minimal **> 8%**.

##### **2. Efisiensi biaya marketing**

* Pengurangan biaya promosi karena targeting lebih tepat â†’ **> 15%** efisiensi.

##### **3. Peningkatan engagement**

* Frekuensi transaksi naik **> 5%** untuk segmen tertentu.
* Atau peningkatan saldo rata-rata pada segmen high-value.

##### **4. Peningkatan akurasi segmentasi operasional**

* Tim marketing atau risk bisa mengidentifikasi segmen dengan benar minimal **> 90%** berdasarkan rule cluster.

## **ğŸ—‚ï¸ Dataset**
### **Sumber Dataset**
 **Primary Source**: [Bank Transaction Dataset](https://www.kaggle.com/datasets/valakhorasani/bank-transaction-dataset-for-fraud-detection)

### Dataset Overview
```python
Shape: (2512, 16)
Missing Values: 0%
Duplicate Rows: 0%
```

### **Dataset Description**
| Feature                 | Type    | Description                              | Missing Values |
| ----------------------- | ------- | ---------------------------------------- | -------------- |
| TransactionID           | object  | ID unik transaksi                        | 0%             |
| AccountID               | object  | ID nasabah                               | 0%             |
| TransactionAmount       | float64 | Nominal transaksi                        | 0%             |
| TransactionDate         | object  | Tanggal transaksi                        | 0%             |
| TransactionType         | object  | Jenis transaksi (misal: debit/kredit)    | 0%             |
| Location                | object  | Lokasi transaksi                         | 0%             |
| DeviceID                | object  | ID perangkat yang digunakan              | 0%             |
| IP Address              | object  | Alamat IP saat transaksi                 | 0%             |
| MerchantID              | object  | ID merchant                              | 0%             |
| Channel                 | object  | Kanal transaksi (ATM, mobile, web, dll.) | 0%             |
| CustomerAge             | int64   | Usia nasabah                             | 0%             |
| CustomerOccupation      | object  | Pekerjaan nasabah                        | 0%             |
| TransactionDuration     | int64   | Durasi proses transaksi                  | 0%             |
| LoginAttempts           | int64   | Jumlah percobaan login sebelum transaksi | 0%             |
| AccountBalance          | float64 | Saldo rekening saat transaksi            | 0%             |
| PreviousTransactionDate | object  | Tanggal transaksi sebelumnya             | 0%             |
| Cluster                 | int64   | Label cluster hasil unsupervised model   | 0%             |


## ğŸ—ï¸ Struktur Projek
```
data_science_project/
â”œâ”€â”€ conf/                          # Configuration data catalog
â”‚   â”œâ”€â”€ base/                      # Base configuration
â”‚   â”‚   â”œâ”€â”€ catalog.yml
â”‚   â”‚   â”œâ”€â”€ parameters_data_EDA.yml
â”‚   â”‚   â””â”€â”€ parameters_model_training.yml
â”‚   â”œâ”€â”€ dev/                       # Development configuration
â”‚   â”‚   â”œâ”€â”€ catalog.yml
â”‚   â”‚   â”œâ”€â”€ parameters_data_EDA.yml
â”‚   â”‚   â””â”€â”€ parameters_model_training.yml
â”‚   â””â”€â”€ prod/                      # Production configuration
â”‚       â”œâ”€â”€ catalog.yml
â”‚       â”œâ”€â”€ parameters_data_EDA.yml
â”‚       â””â”€â”€ parameters_model_training.yml
â”œâ”€â”€ data/                          # Data storage
â”‚   â”œâ”€â”€ 01_raw/                    # data asli atau mentah
â”‚   â”‚   â”œâ”€â”€ train.csv
â”‚   â”‚   â”œâ”€â”€ test.csv
â”‚   â”‚   â””â”€â”€ external_data.csv
â”‚   â”œâ”€â”€ 02_Intermediate/           # data yang sudah clean
â”‚   â”‚   â”œâ”€â”€ train_cleaned.csv
â”‚   â”‚   â”œâ”€â”€ test_cleaned.csv
â”‚   â”‚   â””â”€â”€ feature_engineered.csv
â”‚   â”œâ”€â”€ 03_primary/                # data yang sudah siap untuk preproses
â”‚   â””â”€â”€ 04_feature/                # data yang dihasilkan dari feature engineering
|   â””â”€â”€ 05_model_input/            # data yang siap untuk model training
â”‚
â”œâ”€â”€ docs/                          # Documentation
|
â”œâ”€â”€ models/                        # Model storage
|                      
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_eda.ipynb               # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â”œâ”€â”€ 04_model_evaluation.ipynb
â”‚   â””â”€â”€ 05_interpretation.ipynb
â”‚
â”œâ”€â”€ reports/                       # Report storage
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ project_name/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”‚   â”œâ”€â”€ data_cleaning/     # pipeline data cleaning/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ nodes.py       # preprocess, cleaning
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_EDA/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ nodes.py       # EDA, feature engineering
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_evaluation/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ nodes.py       # model evaluation
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”‚   â”‚   â””â”€â”€ data_modeling/
â”‚   â”‚   â”‚   |   â”œâ”€â”€ nodes.py       # model training
â”‚   â”‚   â”‚   |   â””â”€â”€ pipeline.py
â”‚   â”‚   â”‚   â””â”€â”€ data_preproses/
â”‚   â”‚   â”‚       â”œâ”€â”€ nodes.py       # data preproses
â”‚   â”‚   â”‚       â””â”€â”€ pipeline.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ __main__.py            # Project entry point
â”‚   â”‚   â””â”€â”€ pipeline_registry.py   # Pipeline registry
â”‚   â”‚   â””â”€â”€ setings.py             # Project settings
â”‚   â”‚  
â”‚   â”‚   
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚
â”‚   â””â”€â”€ setup.py                   # Project metadata
â”‚
â”œâ”€â”€ tests/                         # Unit tests
â”‚   â”œâ”€â”€ pipelines/
|   â”‚   â”œâ”€â”€ data_cleaning/
â”‚   â”‚   â”œâ”€â”€ data_EDA/
â”‚   â”‚   â”œâ”€â”€ data_evaluation/
â”‚   â”‚   â”œâ”€â”€ data_modeling/
â”‚   â”‚   â””â”€â”€ data_preproses/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ environment.yml                # Conda environment
â”œâ”€â”€ pyproject.toml                 # Project configuration
â”œâ”€â”€ setup.py                       # Package setup
â”œâ”€â”€ .env.example                   # Environment variables template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## âš™ï¸ Instalasi dan Setup

### Prerequisites
- Python 3.8+
- pip atau conda (direkomendasikan conda)

### 1. Clone Repository
```bash
git clone https://github.com/TurmaeUrsorum/bank-transaction-user-classification
cd bank-transaction-user-classification
```

### 2. Setup Environment

**Option A: menggunakan conda (sangat direkomendasikan)**
```bash
conda env create -f environment.yml
conda activate ds-project
```

**Option B: menggunakan pip**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# atau
venv\Scripts\activate     # Windows

# harus convert sendiri ke requirements.txt
pip install -r requirements.txt
```

## ğŸš€ Penggunaan

### Quick Start

1. Clone repository
2. Setup environment
3. Jalankan `kedro run`

```bash
# semua pipeline dijalankan
kedro run
# run kedro dengan parallel
kedro run --runner ParallelRunner
# run kedro spesifik pipeline
kedro run --pipeline data_EDA
```
## ğŸ”¬ Metodologi

### Data Preprocessing
- **Handling Missing Values**: [Technique yang digunakan]
- **Outlier Treatment**: [Method untuk handle outliers]
- **Encoding**: [Label encoding, One-hot encoding, etc.]
- **Scaling**: [Standardization/Normalization method]

### Feature Engineering
- **Created Features**: [feature yang dibuat amount to balance ratio dan multiple login flag ]

